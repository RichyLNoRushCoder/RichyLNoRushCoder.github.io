<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>2026 开年王炸：从 Clawdbot 到 Moltbot，真正的个人 AI 时代来了？</title>
    <link href="/2026/02/01/Clawdbot-20260201/"/>
    <url>/2026/02/01/Clawdbot-20260201/</url>
    
    <content type="html"><![CDATA[<h2 id="GitHub-两周-100k-Star：聊聊最近火出圈的-Moltbot（原-Clawdbot）"><a href="#GitHub-两周-100k-Star：聊聊最近火出圈的-Moltbot（原-Clawdbot）" class="headerlink" title="GitHub 两周 100k Star：聊聊最近火出圈的 Moltbot（原 Clawdbot）"></a>GitHub 两周 100k Star：聊聊最近火出圈的 Moltbot（原 Clawdbot）</h2><p>最近两周，技术圈几乎被一个叫 <strong>Clawdbot</strong>（现更名为 <strong>Moltbot</strong>）的项目刷屏了。</p><p>数据也很直观：<strong>2 周内 Star 突破 100k</strong>。对比 LangChain、Dify 这类“老牌选手”，Moltbot 的增长曲线几乎是垂直往上冲的。一般这种热度，背后多半是它刚好戳中了某个长期没被好好解决的痛点。</p><p><img src="/images/Knowledge/Agent/Clawdbot/Githubstars.svg" alt="github-stars"></p><h3 id="1）它到底解决了什么问题？"><a href="#1）它到底解决了什么问题？" class="headerlink" title="1）它到底解决了什么问题？"></a>1）它到底解决了什么问题？</h3><p>一句话概括：Moltbot 不是另一个“网页版对话框”，而是一个<strong>跑在本地的系统级 Agent 网关</strong>。</p><p>传统 ChatGPT &#x2F; Claude 更像“被动式问答”：你问一句，它回一句。<br>而 Moltbot 的定位更像“数字管家”：它常驻在你的电脑后台，通过 API 把日历、邮件、Slack，甚至本地文件系统这些能力串起来，让 AI 不止能聊，还能“做事”。</p><h3 id="2）核心差异：从“对话框”到“工作流”"><a href="#2）核心差异：从“对话框”到“工作流”" class="headerlink" title="2）核心差异：从“对话框”到“工作流”"></a>2）核心差异：从“对话框”到“工作流”</h3><p>对开发者来说，Moltbot 真正吸引人的点，通常不在“能不能写诗”，而在它的三套底层逻辑：</p><ul><li><p><strong>主动性（Proactive）</strong><br>这是一个很关键的变化：它会根据日历节点、任务状态主动来找你。比如检测到你 30 分钟后有会议，它可能会在 Telegram 上问你要不要整理背景资料，而不是等你想起来去问它。</p></li><li><p><strong>本地化记忆（Long-term Memory）</strong><br>它会在本地维护一个 <code>MEMORY.md</code>。这意味着随着使用时间增加，它会慢慢摸清你的技术栈偏好、项目背景、写作口吻。更像是在本地搭一个“个人知识库”，而不是简单把上下文塞长一点。</p></li><li><p><strong>隐私与权限控制</strong><br>哪怕它调用闭源模型（Claude &#x2F; Gemini）来做推理，但任务编排、敏感数据存储都在本地完成。对数据敏感、或者习惯把工作资料放在本地的同学来说，这种“逻辑本地化”的方案，比全云端助手更让人安心。</p></li></ul><p>更细的技术细节我放在另一篇文章里：<br><a href="https://norushcoder.com/2026/02/01/Details-Of-Clawdbot-20260201/">2026 开年王炸：从 Clawdbot 到 Moltbot，真正的个人 AI 时代来了？（技术细节）</a></p><hr><h3 id="3）快速部署并使用（保姆级）"><a href="#3）快速部署并使用（保姆级）" class="headerlink" title="3）快速部署并使用（保姆级）"></a>3）快速部署并使用（保姆级）</h3><p>下面按“能跑起来”为第一目标来走一遍。</p><h4 id="3-1-前置依赖"><a href="#3-1-前置依赖" class="headerlink" title="3.1 前置依赖"></a>3.1 前置依赖</h4><p>Moltbot 依赖 <strong>Node.js</strong> 和 <strong>Git</strong>（以及包管理工具）。先确认你本机装好了：</p><ul><li>Node.js：JavaScript 运行环境</li><li>npm：Node.js 的包管理工具</li><li>Git：版本控制工具</li></ul><p>装完后在终端里确认版本号能正常输出：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">node -v<br>npm -v<br>git -v<br></code></pre></td></tr></table></figure><p>只要能看到对应的版本号，就 OK。</p><hr><h4 id="3-2-克隆仓库（推荐浅克隆）"><a href="#3-2-克隆仓库（推荐浅克隆）" class="headerlink" title="3.2 克隆仓库（推荐浅克隆）"></a>3.2 克隆仓库（推荐浅克隆）</h4><p>先把代码拉下来：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/openclaw/openclaw.git<br></code></pre></td></tr></table></figure><p>如果你只是想体验功能，不想拉全量历史，直接用浅克隆就够了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> --depth 1 https://github.com/openclaw/openclaw.git<br></code></pre></td></tr></table></figure><p>看到类似下面这种输出，说明下载完成：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text">Cloning into &#x27;openclaw&#x27;...<br>remote: Enumerating objects: 5032, done.<br>...<br>Resolving deltas: 100% (337/337), done.<br></code></pre></td></tr></table></figure><p>进入目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> openclaw<br></code></pre></td></tr></table></figure><hr><h4 id="3-3-安装依赖（推荐-pnpm）"><a href="#3-3-安装依赖（推荐-pnpm）" class="headerlink" title="3.3 安装依赖（推荐 pnpm）"></a>3.3 安装依赖（推荐 pnpm）</h4><p>项目使用 <strong>pnpm</strong>，它比 npm 更快、更省空间（不少前端项目基本都换到 pnpm 了）。</p><p>安装依赖：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pnpm install<br></code></pre></td></tr></table></figure><p>看到类似下面这种日志，基本就表示装好了：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs text">packages/clawdbot postinstall$ node ./scripts/postinstall.js<br>│ clawdbot renamed -&gt; openclaw<br>...<br>Done in 8m 23.5s using pnpm v10.23.0<br></code></pre></td></tr></table></figure><hr><h4 id="3-4-构建-UI-编译-授权常驻"><a href="#3-4-构建-UI-编译-授权常驻" class="headerlink" title="3.4 构建 UI + 编译 + 授权常驻"></a>3.4 构建 UI + 编译 + 授权常驻</h4><p>接下来三步走：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">pnpm ui:build<br>pnpm build<br>openClaw onboard --install-daemon<br></code></pre></td></tr></table></figure><p>简单解释一下各自做什么：</p><ul><li><code>pnpm ui:build</code>：构建开发者打包好的控制面板 UI</li><li><code>pnpm build</code>：编译整体项目</li><li><code>openClaw onboard --install-daemon</code>：引导授权 + 注册为系统常驻（Daemon）</li></ul><p>UI 编译成功通常会看到类似：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">vite v7.3.1 building client environment for production...<br>✓ built in 580ms<br></code></pre></td></tr></table></figure><p>再往下你可能还会看到 bundle 和 hook metadata 复制的日志，这些都属于正常输出。</p><hr><h4 id="3-5-Onboarding：按向导配置（第一次建议-QuickStart）"><a href="#3-5-Onboarding：按向导配置（第一次建议-QuickStart）" class="headerlink" title="3.5 Onboarding：按向导配置（第一次建议 QuickStart）"></a>3.5 Onboarding：按向导配置（第一次建议 QuickStart）</h4><p>运行 onboarding 后，第一屏会是安全声明，认真看一遍（尤其你准备开文件&#x2F;工具权限的话）。确认后选 <code>Yes</code> 继续：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">I understand this is powerful and inherently risky. Continue?<br>○ Yes / ● No<br></code></pre></td></tr></table></figure><p>接下来是配置模式：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">Onboarding mode<br>● QuickStart (Configure details later via openclaw configure.)<br>○ Manual<br></code></pre></td></tr></table></figure><ul><li><strong>QuickStart（推荐新手）</strong>：先跑起来，细节以后再改</li><li><strong>Manual</strong>：每一项都让你自己填（端口、存储路径、自启、插件开关……），适合强迫症&#x2F;重度玩家</li></ul><p>第一次我建议直接 QuickStart，省心。</p><hr><h4 id="3-6-选择模型-Provider-填-API-Key"><a href="#3-6-选择模型-Provider-填-API-Key" class="headerlink" title="3.6 选择模型 Provider + 填 API Key"></a>3.6 选择模型 Provider + 填 API Key</h4><p>向导里会让你选择模型&#x2F;鉴权 Provider，比如 OpenAI &#x2F; Anthropic &#x2F; Google 等。</p><p>如果你手里是 DeepSeek 之类兼容 OpenAI 接口的 Token，可以先选 OpenAI（兼容模式），然后在模型名那里手动填。</p><p>配置过程大概是：</p><ul><li>选 Provider（例如 OpenAI）</li><li>输入 API Key</li><li>选默认模型（如果列表里没有你想要的，就选 <code>Enter model manually</code>）</li></ul><p>比如你最后可能会输入：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">openai/deepseek-chat<br></code></pre></td></tr></table></figure><p>如果向导提示“解析不到模型”，也别慌，后面我们可以直接改配置文件。</p><hr><h4 id="3-7-选择消息通道：以-Discord-为例"><a href="#3-7-选择消息通道：以-Discord-为例" class="headerlink" title="3.7 选择消息通道：以 Discord 为例"></a>3.7 选择消息通道：以 Discord 为例</h4><p>向导会让你选一个消息通道（Telegram &#x2F; Discord &#x2F; Slack 等）。这里以 Discord 为例，因为确实更常见。</p><p>它会提示你输入 Discord bot token，<br>bottoken 获取方式<br>简单来说：</p><ol><li>去 Discord Developer Portal 创建应用</li><li>Bot → Add Bot → Reset Token → 复制 token</li></ol><p>图示例：<br>进入<a href="https://discord.com/developers/applications">开发者模式</a><br><img src="/images/Knowledge/Agent/Clawdbot/step1.png" alt="Step1"><br><img src="/images/Knowledge/Agent/Clawdbot/step2.png" alt="Step2"><br><img src="/images/Knowledge/Agent/Clawdbot/step3.png" alt="Step3"></p><p>你把 token 填进去后，可以选择频道访问策略。建议用 <strong>Allowlist（白名单）</strong>，只让 bot 监听指定频道，风险更可控。</p><p>最后会看到类似：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs text">Updated ~/.openclaw/openclaw.json<br>Workspace OK: ~/.openclaw/workspace<br>Sessions OK: ~/.openclaw/agents/main/sessions<br></code></pre></td></tr></table></figure><hr><h4 id="3-8-安装技能依赖（可选项）"><a href="#3-8-安装技能依赖（可选项）" class="headerlink" title="3.8 安装技能依赖（可选项）"></a>3.8 安装技能依赖（可选项）</h4><p>向导会让你安装一些技能依赖，比如 apple-reminders、summarize 之类，按需装就行。</p><p>中途可能会问你要不要填 <code>GOOGLE_PLACES_API_KEY</code>，如果你暂时用不到地点能力，直接选 <code>No</code> 跳过即可。</p><p>接下来会出现 Hooks 选择：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">Enable hooks?<br>◻ Skip for now<br>◻ 🚀 boot-md<br>◻ 📝 command-logger<br>◻ 💾 session-memory<br></code></pre></td></tr></table></figure><p>这里我建议<strong>全勾选</strong>：</p><ul><li>boot-md：出厂 prompt&#x2F;基础引导</li><li>command-logger：记录日志</li><li>session-memory：长久记忆（这才是“能越用越懂你”的关键）</li></ul><p>不勾的话体验会很像“普通聊天机器人”。</p><hr><h3 id="4）手动修改配置（以-DeepSeek-为例）"><a href="#4）手动修改配置（以-DeepSeek-为例）" class="headerlink" title="4）手动修改配置（以 DeepSeek 为例）"></a>4）手动修改配置（以 DeepSeek 为例）</h3><p>配置文件在：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~/.openclaw/openclaw.json<br></code></pre></td></tr></table></figure><p>如果你在向导里填的模型名没被识别，或者需要补充 provider，可以直接在 <code>models.providers</code> 里补配置，然后把默认模型指向它。</p><p>你的配置文件大概长这样：<br>好，这个<strong>必须放</strong>，而且我帮你稍微整理了一下结构和注释，<strong>原汁原味但更像人写的配置示例</strong>，读者可以直接对着抄，不容易踩坑。</p><p>你可以在正文里这样写👇</p><hr><h5 id="完整配置文件示例（以-DeepSeek-Discord-为例）"><a href="#完整配置文件示例（以-DeepSeek-Discord-为例）" class="headerlink" title="完整配置文件示例（以 DeepSeek + Discord 为例）"></a>完整配置文件示例（以 DeepSeek + Discord 为例）</h5><p>如果你在 Onboarding 阶段没法直接识别 DeepSeek 模型，或者后面想精细控制模型、频道、权限，<strong>最稳妥的方式就是直接改配置文件</strong>。</p><p>配置文件路径：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">~/.openclaw/openclaw.json<br></code></pre></td></tr></table></figure><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;meta&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;lastTouchedVersion&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2026.1.30&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lastTouchedAt&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2026-02-03T02:06:28.979Z&quot;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-attr">&quot;wizard&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;lastRunAt&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2026-02-02T03:36:07.817Z&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lastRunVersion&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;2026.1.30&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lastRunCommand&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;onboard&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;lastRunMode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;local&quot;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-comment">/* =========================</span><br><span class="hljs-comment">   * 模型配置（DeepSeek 示例）</span><br><span class="hljs-comment">   * ========================= */</span><br>  <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;mode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;merge&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;providers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;deepseek&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;baseUrl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;https://api.deepseek.com/v1&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;apiKey&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的_DEEPSEEK_API_KEY&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;api&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;openai-completions&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>          <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;id&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;deepseek-chat&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;DeepSeek Chat&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;reasoning&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;text&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;contextWindow&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">200000</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;maxTokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8192</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;cost&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;input&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;output&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;cacheRead&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;cacheWrite&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">]</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-comment">/* =========================</span><br><span class="hljs-comment">   * Agent 默认行为</span><br><span class="hljs-comment">   * ========================= */</span><br>  <span class="hljs-attr">&quot;agents&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;defaults&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;primary&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;deepseek/deepseek-chat&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;models&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;deepseek/deepseek-chat&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;workspace&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;/Users/你的用户名/.openclaw/workspace&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;maxConcurrent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;subagents&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;maxConcurrent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">8</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-comment">/* =========================</span><br><span class="hljs-comment">   * 消息 &amp; 指令行为</span><br><span class="hljs-comment">   * ========================= */</span><br>  <span class="hljs-attr">&quot;messages&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;ackReactionScope&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;group-mentions&quot;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-attr">&quot;commands&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;native&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;auto&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;nativeSkills&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;auto&quot;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-comment">/* =========================</span><br><span class="hljs-comment">   * Hooks（强烈建议开启）</span><br><span class="hljs-comment">   * ========================= */</span><br>  <span class="hljs-attr">&quot;hooks&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;internal&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;entries&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;boot-md&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span> <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;command-logger&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span> <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;session-memory&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span> <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-comment">/* =========================</span><br><span class="hljs-comment">   * Discord 通道配置</span><br><span class="hljs-comment">   * ========================= */</span><br>  <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;discord&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;token&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;你的_DISCORD_BOT_TOKEN&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;groupPolicy&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;allowlist&quot;</span><span class="hljs-punctuation">,</span><br><br>      <span class="hljs-attr">&quot;dm&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;policy&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pairing&quot;</span><br>      <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>      <span class="hljs-attr">&quot;guilds&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;你的服务器ID&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>          <span class="hljs-attr">&quot;requireMention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;users&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;你的用户ID&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>          <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;你的频道ID&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>              <span class="hljs-attr">&quot;allow&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>              <span class="hljs-attr">&quot;requireMention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br>            <span class="hljs-punctuation">&#125;</span><br>          <span class="hljs-punctuation">&#125;</span><br>        <span class="hljs-punctuation">&#125;</span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-comment">/* =========================</span><br><span class="hljs-comment">   * Gateway（本地网关）</span><br><span class="hljs-comment">   * ========================= */</span><br>  <span class="hljs-attr">&quot;gateway&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;port&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">18789</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;mode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;local&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;bind&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;loopback&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;auth&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;mode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;token&quot;</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;token&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;系统自动生成&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-comment">/* =========================</span><br><span class="hljs-comment">   * 技能 &amp; 插件</span><br><span class="hljs-comment">   * ========================= */</span><br>  <span class="hljs-attr">&quot;skills&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;install&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;nodeManager&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;pnpm&quot;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br><br>  <span class="hljs-attr">&quot;plugins&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;entries&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;discord&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;enabled&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><br>      <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><hr><h3 id="配置里几个最容易踩坑的点"><a href="#配置里几个最容易踩坑的点" class="headerlink" title="配置里几个最容易踩坑的点"></a>配置里几个<strong>最容易踩坑的点</strong></h3><ul><li><p><strong>模型名一定要和 <code>providers</code> 里保持一致</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-attr">&quot;primary&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;deepseek/deepseek-chat&quot;</span><br></code></pre></td></tr></table></figure></li><li><p>Discord 如果开了 <code>requireMention: true</code><br>👉 <strong>必须 @ 机器人它才会回</strong></p></li><li><p>Hooks 不开 &#x3D; 基本退化成聊天窗口<br>👉 想要「长期记忆 &#x2F; 自动化」，<code>session-memory</code> 必开</p></li><li><p><code>gateway.port</code> 默认是本地端口<br>👉 Web 面板地址一般是</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">http:</span><span class="hljs-comment">//127.0.0.1:18789/</span><br></code></pre></td></tr></table></figure></li></ul><hr><p>想了解配置文件的规则，可以参考这几个文档&#x2F;openclaw&#x2F;docs&#x2F;channels&#x2F;discord.md、&#x2F;openclaw&#x2F;docs&#x2F;concepts&#x2F;model-providers.md、&#x2F;Users&#x2F;guolixin&#x2F;Desktop&#x2F;progress&#x2F;code&#x2F;Clawdbot&#x2F;openclaw&#x2F;docs&#x2F;gateway&#x2F;configuration.md，都在你的 <code>openclaw</code> 文件夹里。</p><h3 id="5）把机器人拉进-Discord-服务器（关键几步）"><a href="#5）把机器人拉进-Discord-服务器（关键几步）" class="headerlink" title="5）把机器人拉进 Discord 服务器（关键几步）"></a>5）把机器人拉进 Discord 服务器（关键几步）</h3><p>这里再把 Discord 的“容易漏”的点捋一下：</p><ol><li><p><strong>开启 Message Content Intent</strong><br>Discord Developer Portal → 你的应用 → Bot → Privileged Gateway Intents<br>把 <strong>Message Content Intent</strong> 打开，保存 → 在Oauth2界面配置权限</p></li><li><p><strong>生成邀请链接</strong><br>OAuth2 → URL Generator<br>Scopes 勾选：<code>bot</code>、<code>applications.commands</code><br>Bot Permissions 勾选你需要的权限（省事可直接 Administrator；谨慎点就最小权限）<br><img src="/images/Knowledge/Agent/Clawdbot/oauth.png" alt="Step4"><br><img src="/images/Knowledge/Agent/Clawdbot/step5.png" alt="Step5"><br><img src="/images/Knowledge/Agent/Clawdbot/step6.png" alt="Step6"><br><img src="/images/Knowledge/Agent/Clawdbot/step7.png" alt="Step7"><br><img src="/images/Knowledge/Agent/Clawdbot/step8.png" alt="Step8"><br><img src="/images/Knowledge/Agent/Clawdbot/step9.png" alt="Step9"></p></li><li><p><strong>邀请进服务器</strong><br>复制 Generated URL，浏览器打开，选择服务器，Authorize 完成授权。</p></li></ol><hr><h3 id="6）启动网关：本地面板-Discord-对话"><a href="#6）启动网关：本地面板-Discord-对话" class="headerlink" title="6）启动网关：本地面板 + Discord 对话"></a>6）启动网关：本地面板 + Discord 对话</h3><p>最后启动服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">openclaw gateway start<br></code></pre></td></tr></table></figure><p>然后你可以：</p><ul><li>访问本地面板：<code>http://127.0.0.1:18789/</code></li><li>或者在 Discord 里 @ 机器人对话（如果你开启了 requireMention 就必须 @）</li></ul><p><img src="/images/Knowledge/Agent/Clawdbot/result.png" alt="效果图"></p>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Agent</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>LLM</tag>
      
      <tag>Data</tag>
      
      <tag>Agent</tag>
      
      <tag>数据人快速学 AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2026 开年王炸：从 Clawdbot 到 Moltbot，真正的个人 AI 时代来了？(技术细节)</title>
    <link href="/2026/02/01/Details-Of-Clawdbot-20260201/"/>
    <url>/2026/02/01/Details-Of-Clawdbot-20260201/</url>
    
    <content type="html"><![CDATA[<h1 id="Clawdbot-架构全解：一个“永远在线”的-Agent-系统是如何工作的"><a href="#Clawdbot-架构全解：一个“永远在线”的-Agent-系统是如何工作的" class="headerlink" title="Clawdbot 架构全解：一个“永远在线”的 Agent 系统是如何工作的"></a>Clawdbot 架构全解：一个“永远在线”的 Agent 系统是如何工作的</h1><p>如果你想部署或体验 Clawdbot，可以先参考我的博客：<br>👉 <a href="https://norushcoder.com/2026/02/01/Clawdbot-20260201/">GitHub 两周 100k Star：聊聊最近火出圈的 Moltbot (原 Clawdbot)</a></p><p>这篇文章不讲安装命令，而是从<strong>系统设计和工程实现</strong>的角度，完整拆解 Clawdbot 是如何构建一个「多 Agent、跨设备、具备长期记忆和主动行为能力」的 AI 系统的。</p><hr><h2 id="一、整体架构：Clawdbot-的五大核心组件"><a href="#一、整体架构：Clawdbot-的五大核心组件" class="headerlink" title="一、整体架构：Clawdbot 的五大核心组件"></a>一、整体架构：Clawdbot 的五大核心组件</h2><p>Clawdbot 采用了一个非常清晰的分层架构：</p><ul><li><strong>Gateway（中控调度）</strong></li><li><strong>Agent（智能体）</strong></li><li><strong>Skills（技能 &#x2F; 工具箱）</strong></li><li><strong>Channels（消息通道）</strong></li><li><strong>Nodes（终端 &#x2F; 传感器）</strong></li></ul><p>这种设计的核心目标只有三个词：<strong>可扩展、可组合、可控</strong>。</p><h3 id="1-Gateway：真正的“中控大脑”"><a href="#1-Gateway：真正的“中控大脑”" class="headerlink" title="1. Gateway：真正的“中控大脑”"></a>1. Gateway：真正的“中控大脑”</h3><p>在 OpenClaw（早期也叫 Moltbot）的设计中，Gateway 并不是一个简单的 API Server，而是整个系统的<strong>控制平面</strong>。</p><p>它主要负责三件事：</p><ul><li><p><strong>会话管理</strong><br>创建和维护 Session ID，管理上下文、生命周期和消息归属。</p></li><li><p><strong>请求路由</strong><br>OpenClaw 是一个多 Agent、多 Channel 的系统。<br>Gateway 决定：</p><ul><li>消息从哪个 Channel 进来</li><li>应该交给哪个 Agent</li><li>是否需要多个 Agent 协作</li></ul></li><li><p><strong>安全与权限控制</strong><br>包括：</p><ul><li>本地 &#x2F; 远程请求隔离</li><li>API 权限管理</li><li>通道白名单</li><li>远程连接的安全边界</li></ul></li></ul><p>你可以把 Gateway 理解成一个 <strong>“带状态、懂业务的智能路由器”</strong>。</p><hr><h3 id="2-Agent：真正干活的人"><a href="#2-Agent：真正干活的人" class="headerlink" title="2. Agent：真正干活的人"></a>2. Agent：真正干活的人</h3><p>Agent 是执行任务的主体，每个 Agent 都是一个完整的 <strong>思考–行动循环（Agent Loop）</strong>。</p><p>典型流程只有四步：</p><ol><li>上下文组装</li><li>模型推理</li><li>工具（Skill）调用</li><li>结果分发</li></ol><p>Clawdbot 支持 <strong>多 Agent 并行</strong>：</p><ul><li>可以彼此完全隔离</li><li>也可以通过 Gateway 协作</li></ul><p>每个 Agent 都有自己的工作区、配置和记忆文件，互不污染。</p><h4 id="Pi-Agent：一个极其克制的“编程智能体”"><a href="#Pi-Agent：一个极其克制的“编程智能体”" class="headerlink" title="Pi Agent：一个极其克制的“编程智能体”"></a>Pi Agent：一个极其克制的“编程智能体”</h4><p>Clawdbot 里最有意思的是 <strong>Pi Agent</strong>。</p><p>它不是靠“全能 Prompt”，而是通过<strong>极小、极严谨的工具集合</strong>，用一套非常精妙的<strong>指令设计</strong>，被塑造成一个非常可靠的编程与系统操作智能体。</p><p>核心工具只有 4 个：</p><ul><li><code>bash</code>：执行 shell 命令</li><li><code>read</code>：读取文件</li><li><code>write</code>：写文件</li><li><code>edit</code>：编辑文件</li></ul><p>工具越少，<strong>行为越可预测</strong>。<br>这是 Clawdbot 在工程层面非常成熟的一点。</p><hr><h3 id="3-Skills：能力的渐进式封装"><a href="#3-Skills：能力的渐进式封装" class="headerlink" title="3. Skills：能力的渐进式封装"></a>3. Skills：能力的渐进式封装</h3><p>Skills 是 Agent 能“做什么”的说明书。</p><p>在 OpenClaw 中，Skills 遵循 <strong>AgentSkills 规范</strong>（Anthropic 提出的开放标准），目前已经被：</p><ul><li>Claude Code</li><li>Cursor</li><li>VS Code</li><li>OpenAI Codex</li><li>Gemini CLI</li><li>GitHub Copilot</li></ul><p>等大量工具采用。</p><p>Skill 本质上是：</p><ul><li>用 Markdown + 脚本描述能力</li><li>按需加载</li><li>渐进式暴露模型能力</li></ul><p>这样做的直接收益是：</p><ul><li><strong>更低的 Token 消耗</strong></li><li><strong>更稳定的推理路径</strong></li></ul><p>更详细的分析我在另一篇博客里写过：<br>👉 <a href="https://norushcoder.com/2026/01/17/Agent-Skills-20260117/">Agent Skills：大模型能力的渐进式封装与按需加载</a></p><hr><h3 id="4-Channels：多平台消息集成"><a href="#4-Channels：多平台消息集成" class="headerlink" title="4. Channels：多平台消息集成"></a>4. Channels：多平台消息集成</h3><p>Channels 的职责很单一：<br><strong>把各种消息平台接到 Gateway 上，并做协议&#x2F;格式翻译。</strong></p><p>目前支持的典型渠道包括：</p><table><thead><tr><th>平台</th><th>协议 &#x2F; 库</th><th>特点</th></tr></thead><tbody><tr><td>WhatsApp</td><td>Baileys</td><td>QR 登录、媒体支持</td></tr><tr><td>Telegram</td><td>grammY</td><td>流式、Webhook</td></tr><tr><td>Discord</td><td>discord.js</td><td>原生命令</td></tr><tr><td>Slack</td><td>Bolt</td><td>DM 策略、频道白名单</td></tr><tr><td>Signal</td><td>signal-cli</td><td>本地运行</td></tr><tr><td>iMessage</td><td>imsg CLI</td><td>仅 macOS</td></tr></tbody></table><blockquote><p>由于微信没有公开 API，目前暂不支持。未来可能会支持飞书或钉钉。</p></blockquote><p><strong>WhatsApp 示例配置：</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;channels&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;whatsapp&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>      <span class="hljs-attr">&quot;allowFrom&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;+15555550123&quot;</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>      <span class="hljs-attr">&quot;groups&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;*&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;requireMention&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span> <span class="hljs-punctuation">&#125;</span> <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;messages&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;groupChat&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;mentionPatterns&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;@clawd&quot;</span><span class="hljs-punctuation">]</span> <span class="hljs-punctuation">&#125;</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><hr><h3 id="5-Nodes：远程大脑，本地双手"><a href="#5-Nodes：远程大脑，本地双手" class="headerlink" title="5. Nodes：远程大脑，本地双手"></a>5. Nodes：远程大脑，本地双手</h3><p>Nodes 是 Clawdbot 最容易被低估、但极其强大的部分。</p><p>它允许你把：</p><ul><li>旧手机</li><li>闲置电脑</li><li>树莓派</li></ul><p>接入整个 Agent 网络，作为<strong>能力节点</strong>。</p><h4 id="Node-能提供什么？"><a href="#Node-能提供什么？" class="headerlink" title="Node 能提供什么？"></a>Node 能提供什么？</h4><table><thead><tr><th>平台</th><th>能力</th></tr></thead><tbody><tr><td>iOS</td><td>摄像头、语音唤醒、屏幕录制</td></tr><tr><td>Android</td><td>摄像头、短信、语音</td></tr><tr><td>macOS</td><td>system.run、通知、摄像头</td></tr></tbody></table><p>通信方式：</p><ul><li>Gateway WebSocket</li><li>LAN &#x2F; Tailscale &#x2F; SSH 隧道</li></ul><p>这实现了一个非常优雅的架构：</p><blockquote><p><strong>Gateway 在云端运行，操作在设备本地执行</strong></p></blockquote><hr><h2 id="二、Gateway-的通信协议：为什么它“像活的一样”"><a href="#二、Gateway-的通信协议：为什么它“像活的一样”" class="headerlink" title="二、Gateway 的通信协议：为什么它“像活的一样”"></a>二、Gateway 的通信协议：为什么它“像活的一样”</h2><h3 id="1-为什么选-WebSocket？"><a href="#1-为什么选-WebSocket？" class="headerlink" title="1. 为什么选 WebSocket？"></a>1. 为什么选 WebSocket？</h3><p>Moltbot 的控制平面彻底放弃了 HTTP 轮询，转而使用 WebSocket。</p><p>原因很简单：</p><ul><li>双向</li><li>低延迟</li><li>长连接</li></ul><p>而且协议有一个<strong>硬性规则</strong>：</p><blockquote><p><strong>第一帧必须是 <code>connect</code></strong></p></blockquote><p>如果客户端没在第一时间“对暗号”，服务器直接断开连接。<br>这是非常典型的防御式设计。</p><hr><h3 id="2-请求-响应（RPC）"><a href="#2-请求-响应（RPC）" class="headerlink" title="2. 请求 &#x2F; 响应（RPC）"></a>2. 请求 &#x2F; 响应（RPC）</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;req&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;id&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;method&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;params&quot;</span> <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;res&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;id&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;ok&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;payload | error&quot;</span> <span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><p>这里的关键是 <code>id</code>。</p><p>WebSocket 是并行的，多个请求同时在路上，<code>id</code> 就是 <strong>TraceID &#x2F; Correlation ID</strong>，用来保证前后对应。</p><hr><h3 id="3-事件驱动（Pub-Sub）"><a href="#3-事件驱动（Pub-Sub）" class="headerlink" title="3. 事件驱动（Pub&#x2F;Sub）"></a>3. 事件驱动（Pub&#x2F;Sub）</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;event&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;event&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;payload&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;seq?&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;stateVersion?&quot;</span> <span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure><ul><li><code>seq</code>：保证事件有序</li><li><code>stateVersion</code>：增量同步，避免全量刷新 UI</li></ul><p>这套设计本质上就是一套 <strong>轻量级流处理协议</strong>。</p><hr><h2 id="三、记忆系统：文件即真理"><a href="#三、记忆系统：文件即真理" class="headerlink" title="三、记忆系统：文件即真理"></a>三、记忆系统：文件即真理</h2><p>这是 Clawdbot 最“反主流”的设计之一。</p><h3 id="1-存储结构"><a href="#1-存储结构" class="headerlink" title="1. 存储结构"></a>1. 存储结构</h3><p>所有记忆都在本地文件系统：</p><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dos">~/clawd/<br>├── IDENTITY.<span class="hljs-built_in">md</span><br>├── SOUL.<span class="hljs-built_in">md</span><br>├── TOOLS.<span class="hljs-built_in">md</span><br>└── memory/<br>    ├── <span class="hljs-number">2026</span>-<span class="hljs-number">02</span>-<span class="hljs-number">01</span>.<span class="hljs-built_in">md</span><br></code></pre></td></tr></table></figure><p>你可以直接用 VS Code 打开、修改。</p><p><strong>你改了什么，AI 就真的记住了什么。</strong></p><hr><h3 id="2-检索机制：BM25-向量混合"><a href="#2-检索机制：BM25-向量混合" class="headerlink" title="2. 检索机制：BM25 + 向量混合"></a>2. 检索机制：BM25 + 向量混合</h3><ul><li>向量搜索（0.7）：语义相似</li><li>BM25（0.3）：精确匹配</li></ul><p>底层使用 <strong>SQLite-vec</strong>，无需部署独立向量数据库。</p><hr><h3 id="3-静默刷新（Silent-Agent-Round）"><a href="#3-静默刷新（Silent-Agent-Round）" class="headerlink" title="3. 静默刷新（Silent Agent Round）"></a>3. 静默刷新（Silent Agent Round）</h3><p>当上下文快满时：</p><ul><li>AI 不回你</li><li>先总结</li><li>写入 <code>memory/*.md</code></li></ul><p>下次通过 RAG 再加载。</p><p>这解决了 <strong>“长对话一定会忘事”</strong> 的老问题。</p><hr><h2 id="四、Heartbeat：让-AI-具备时间感"><a href="#四、Heartbeat：让-AI-具备时间感" class="headerlink" title="四、Heartbeat：让 AI 具备时间感"></a>四、Heartbeat：让 AI 具备时间感</h2><p>Heartbeat 本质是一个 <strong>带推理能力的定时任务系统</strong>。</p><p>配置在 <code>HEARTBEAT.md</code> 里，而不是代码中。</p><p>它可以：</p><ul><li>定时检查日志</li><li>主动发现异常</li><li>在合适的时间联系你（不会半夜骚扰）</li></ul><p>这让 AI 从 <strong>“被动响应”</strong> 进化成 <strong>“主动值班”</strong>。</p><hr><h2 id="五、一个完整工作流示例"><a href="#五、一个完整工作流示例" class="headerlink" title="五、一个完整工作流示例"></a>五、一个完整工作流示例</h2><p><strong>场景：用手机分析家里电脑的 Spark 报错</strong></p><ol><li>Telegram 触发任务</li><li>Pi Agent 制定计划</li><li>bash &#x2F; read &#x2F; write 循环执行</li><li>结果写入长期记忆</li><li>主动反馈给你</li></ol><p>你只发一句话，剩下的全是系统在跑。</p><hr><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>传统 AI 更像是 <strong>“拨号上网”</strong>：你点，它才醒。<br>Clawdbot 更像是 <strong>“永久在线”</strong>：</p><ul><li>有心跳</li><li>有记忆</li><li>有时间感</li><li>有设备边界意识</li></ul><p>它不是在“陪你聊天”，而是在<strong>帮你值班</strong>。</p>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Agent</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>LLM</tag>
      
      <tag>Data</tag>
      
      <tag>Agent</tag>
      
      <tag>数据人快速学 AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>备考雅思:2026-01-29</title>
    <link href="/2026/01/29/English_20260129/"/>
    <url>/2026/01/29/English_20260129/</url>
    
    <content type="html"><![CDATA[<p>今日份学习，加油加油<br><img src="/images/English/data_20260129.png" alt="今日学习数据"><br>今日英语学习依然在第一阶段：打基础+学习阅读技巧</p><ul><li><input disabled="" type="checkbox"> 单词过一遍</li><li><input disabled="" type="checkbox"> 阅读课过一遍</li></ul><h3 id="1-背单词"><a href="#1-背单词" class="headerlink" title="1.背单词"></a>1.背单词</h3><h3 id="2-2-备考雅思阅读方法：part2"><a href="#2-2-备考雅思阅读方法：part2" class="headerlink" title="2.2.备考雅思阅读方法：part2"></a>2.2.备考雅思阅读方法：part2</h3><pre><code class="hljs">解题方法1.填空题：summary\句子填空等等 同义替换结合原文中的逻辑，快速定位答案2.判断题 </code></pre>]]></content>
    
    
    <categories>
      
      <category>备考雅思</category>
      
    </categories>
    
    
    <tags>
      
      <tag>English_Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>向量数据库常见的索引算法和检索算法</title>
    <link href="/2026/01/29/Data-Analysis-Agent-20260129-2/"/>
    <url>/2026/01/29/Data-Analysis-Agent-20260129-2/</url>
    
    <content type="html"><![CDATA[<p>首先做一个总结：</p><h3 id="📊-常见向量索引算法与底层库对比表"><a href="#📊-常见向量索引算法与底层库对比表" class="headerlink" title="📊 常见向量索引算法与底层库对比表"></a>📊 常见向量索引算法与底层库对比表</h3><table><thead><tr><th align="left">类别</th><th align="left">名称</th><th align="left">核心原理</th><th align="left">优势 (Pros)</th><th align="left">劣势 (Cons)</th><th align="left">适用场景</th></tr></thead><tbody><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>IVF</strong></td><td align="left"><strong>聚类分区</strong>：利用 K-Means 将空间划分为小区，搜索时只扫描邻近区域。</td><td align="left">内存占用低，索引速度快。</td><td align="left">搜索精度受限于聚类边界。</td><td align="left">中大规模数据的平衡选型。</td></tr><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>HNSW</strong></td><td align="left"><strong>分层图网络</strong>：构建多层“小世界”导航图，通过层级跳跃快速逼近目标。</td><td align="left"><strong>性能巅峰</strong>，检索延迟极低，召回率极高。</td><td align="left"><strong>内存消耗巨大</strong>，存储成本最高。</td><td align="left">RAG 生产环境、高并发实时检索。</td></tr><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>PQ</strong></td><td align="left"><strong>乘积量化</strong>：将长向量切段并压缩为短编码，实现大幅度“瘦身”。</td><td align="left"><strong>极度省空间</strong>（可压缩 10-100 倍），检索极快。</td><td align="left">精度损失明显，存在语义漂移。</td><td align="left">PB 级海量数据的低成本存储。</td></tr><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>ANNOY</strong></td><td align="left"><strong>随机森林&#x2F;树</strong>：通过随机超平面不断二分空间，构建多棵索引树。</td><td align="left">支持静态文件内存映射（mmap），适合只读。</td><td align="left">不支持增量更新，必须重新构建索引。</td><td align="left">静态推荐系统、离线搜索、移动端。</td></tr><tr><td align="left"><strong>工具库</strong></td><td align="left"><strong>FAISS</strong></td><td align="left"><strong>高性能引擎</strong>：由 Meta 开发，集成了上述所有算法的底层优化库。</td><td align="left">支持 <strong>GPU 加速</strong>，支持多种算法复合（如 IVF-PQ）。</td><td align="left">仅为工具库，非分布式数据库，需二次开发。</td><td align="left">向量数据库底层引擎、算法调优。</td></tr></tbody></table><hr><h4 id="💡-快速选型指南："><a href="#💡-快速选型指南：" class="headerlink" title="💡 快速选型指南："></a>💡 快速选型指南：</h4><ol><li><p><strong>追求极致性能与准确率</strong> 🚀：首选 <strong>HNSW</strong>（目前 RAG 系统的主流）。</p></li><li><p><strong>数据量巨大但内存预算有限</strong> 💰：首选 <strong>IVF-PQ</strong> 组合。</p></li><li><p><strong>数据几乎不更新且需要低内存读写</strong> 🌲：考虑 <strong>ANNOY</strong>。</p></li><li><p><strong>需要进行亿级数据的大规模训练与加速</strong> 🛠️：直接使用 <strong>FAISS</strong>。</p></li><li><p><strong>IVF（Inverted File Index）</strong><br>常见的数据库都支持 IVF 索引。<br>1.1 IVF 索引的存储结构<br>IVF 索引是一种基于倒排索引的数据结构，用于快速查找相似数据。主要有两部分组成，一个是质心表、一个是倒排列表。<br>码表里边存储的是每个聚类的质心向量，同时还会存储这个质心对应的聚类 ID。<br>质心表<br>存储内容：每个聚类的质心向量，和这个聚类其他向量所在倒排列表的地址。<br>存储顺序：根据 Kmeans 聚类的结果输出顺序<br>倒排列表<br>存储内容：质心向量所在聚类的其他向量的 ID 和向量的具体内容。<br>存储顺序：倒排列表内的顺序经常是根据插入顺序排序的。倒排列表之间的顺序通常是按照质心表的顺序<br>1.2 IVF 索引的检索过程<br>IVF 索引的检索过程可以分为以下几个步骤：</p></li><li><p>计算查询向量与所有质心向量的距离，找到距离最近的 K 个质心向量。</p></li><li><p>对于每个最近的质心向量，根据倒排列表找到所有属于该聚类的向量。</p></li><li><p>对这些向量进行距离计算，返回距离最近的 N 个向量。</p></li></ol><p>2.<strong>HNSW (Hierarchical Navigable Small World)</strong><br>2.1 HNSW 索引的存储结构<br>待补充</p>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Data for AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>LLM</tag>
      
      <tag>Data</tag>
      
      <tag>Agent</tag>
      
      <tag>数据人快速学 AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一文读懂什么是 RAG (检索增强生成)及相关技术</title>
    <link href="/2026/01/29/Data-Analysis-Agent-20260129/"/>
    <url>/2026/01/29/Data-Analysis-Agent-20260129/</url>
    
    <content type="html"><![CDATA[<p>本文能够解决：<br>1.快速读懂什么是RAG？</p><p>2.了解 RAG 中会用到的技术：分块、向量化、向量数据库、索引</p><h3 id="1-检索增强生成-RAG-是什么？"><a href="#1-检索增强生成-RAG-是什么？" class="headerlink" title="1. 检索增强生成 (RAG) 是什么？"></a>1. 检索增强生成 (RAG) 是什么？</h3><pre><code class="hljs">在学习一个新知识，我们首先要理解这个这个东西的本质是什么。RAG 检索增强生成（Retrieval Augmented Generat）本质上是一个结合了检索和生成两个任务的 LLM 框架。该框架由两部分构成：向量数据库检索和 LLM 生成。我们在实际生产过程中，大模型的使用经常会遇到以下几个问题：1. 知识的局限性：大模型所使用的知识库往往有限，无法覆盖所有场景，而且大模型使用公开的数据训练的，针对公司特定的业务场景，很难回答一些特定的问题。2. 数据安全性：为了保护公司的隐私数据，我们不能将公司的敏感数据直接上传第三方平台训练通用大模型，但是这样又不能满足公司业务需求。3. 幻觉问题：大模型的生成是基于概率的，而不是基于事实的，这就导致了大模型生成的内容有时是错误的，我们希望大模型在生成的时候能够根据实际业务场景做一次check。RAG 检索增强生成，就是将大模型与向量数据库进行结合，从而解决上述问题。整体的运作模式就是，当用户输入一个问题时，RAG 会先从向量数据库中检索出与问题相关的文档，然后将这些文档作为上下文拼入 prompt 中，输入到大模型中进行生成。</code></pre><h3 id="2-RAG-的主要组件"><a href="#2-RAG-的主要组件" class="headerlink" title="2. RAG 的主要组件"></a>2. RAG 的主要组件</h3><pre><code class="hljs">一个完整的 RAG 应用主要包含两个阶段：    1. 数据准备：将私有的数据提取、文本分割、向量化、然后入库，常见的技术框架是 LlamaIndex、Dify等。    2. 检索：将用户输入的问题作为查询条件，在向量库中查询最相似的数据，将检索到的文档作为上下文,常见的数据库有 Chroma、FAISS、Milvus 等，常见的检索方法有    相似性检索：即计算查询向量与所有存储向量的相似性得分，返回得分高的记录。常见的相似性计算方法包括：余弦相似性、欧氏距离、曼哈顿距离等。    全文检索：全文检索是一种比较经典的检索方式，在数据存入时，通过关键词构建倒排索引；在检索时，通过关键词进行全文检索，找到对应的记录。。    3. 生成：大模型根据上下文生成答案。</code></pre><p>最终一个prompt的大概长这样：</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs armasm">【任务描述】<br>假如你是一个专业的客服机器人，请参考【背景知识】，回<br>【背景知识】<br>&#123;content&#125; <span class="hljs-comment">// 数据检索得到的相关文本</span><br>【问题】<br>石头扫地机器人<span class="hljs-built_in">P10</span>的续航时间是多久？<br></code></pre></td></tr></table></figure><p>具体流程可参照下图。</p><p><img src="/images/Knowledge/Agent/Data_Analysis_Agent/RAG%E6%9E%B6%E6%9E%84%E5%9B%BE.png" alt="RAG模型流程"></p><h3 id="3-具体的技术细节"><a href="#3-具体的技术细节" class="headerlink" title="3.具体的技术细节"></a>3.具体的技术细节</h3><ol><li>数据的处理：分块和向量化技术：<br>Transformer 模型有固定的输入长度限制，因此需要将原始数据进行分块（chunk），分块的方式取决于所使用的嵌入模型和模型可以使用的token容量，通常分块较短的嵌入模型更能捕捉细节，较长的嵌入模型更适合总结类型的任务。</li></ol><p>常见的技术有：</p><table><thead><tr><th>技术类型</th><th>具体方法</th><th>适用场景</th></tr></thead><tbody><tr><td><strong>固定长度分块</strong></td><td>使用字符数或 Token 数（如每 512 Tokens 一块）。通常配合 <strong>10%-20% 的重叠（Overlap）</strong> 使用。</td><td>结构简单的文档、FAQ、初步测试。</td></tr><tr><td><strong>递归字符分块</strong></td><td>根据层级符号（如 <code>\n\n</code>, <code>\n</code>, <code> </code>, <code>&quot;&quot;</code>）尝试切分。</td><td><strong>最推荐的通用方法</strong>。能尽量保持段落和句子的完整性。</td></tr><tr><td><strong>语义分块</strong></td><td>利用 Embedding 模型计算句子间的相似度，当相似度大幅下降时进行切分。</td><td>逻辑紧密的叙述、学术文章。确保每一块都是一个独立的主题。</td></tr><tr><td><strong>层级分块 (Parent-Child)</strong></td><td>将文档切成细小的“子块”用于搜索，但在回答时返回它所属的“大父块”。</td><td>追求极高搜索精度，同时需要丰富上下文的复杂系统。</td></tr><tr><td><strong>特定格式分块</strong></td><td>针对 Markdown（按标题）、HTML（按标签）或代码（按函数&#x2F;类）进行切分。</td><td>开发者文档、代码库、结构化网页。</td></tr></tbody></table><ol start="2"><li>向量化<br>分块之后的数据可以经过embedding向量化，将原始数据映射到向量空间中，向量空间中不同向量的相似度可以表示数据之间的相似性。后续的检索就要通过向量的相似度进行。<br>常见的技术有：</li></ol><ul><li><p><strong>云端 API (高性能&#x2F;长上下文)</strong>：</p></li><li><p>**OpenAI <code>text-embedding-3-small/large**</code>：支持高达 8191 Tokens 的窗口，且支持“维度缩减”技术，性价比极高。</p></li><li><p><strong>Voyage AI &#x2F; Cohere Embed</strong>：在特定领域（如代码、财务）检索精度表现卓越。</p></li><li><p><strong>开源本地模型 (隐私安全&#x2F;高性能)</strong>：</p></li><li><p><strong>BGE 系列 (BAAI)</strong>：中文检索领域的标杆（如 <code>bge-m3</code>），支持多语言和长文本。</p></li><li><p><strong>GTE 系列 (Alibaba)</strong>：在 MTEB 排行榜上长期领先，尤其擅长处理长文档。</p></li><li><p><strong>Jina Embeddings</strong>：目前少数支持 8k 甚至更长上下文的开源模型之一。</p></li></ul><p>一个具体的文本 embedding 过程实际上就是 Transformer 的 Encoder 阶段，文本转向量、注入位置编码、通过 Multi-Head Attention 层和 Feed-Forward 层进行处理，最终输出一个向量表示。<br>以输入 <strong>“我爱你”</strong> 为例，假设模型维度 $d_{model} &#x3D; 768$。</p><ol><li>词法解析阶段 (Tokenization)<br>原始文本被切分为 Token，并映射为词典中的数字 ID。</li></ol><ul><li><strong>输入</strong>：<code>&quot;我爱你&quot;</code></li><li><strong>转换</strong>：<code>[2769, 2302, 872]</code> </li><li><strong>维度</strong>：$1 \times 3$ (1行，3个词)</li></ul><ol start="2"><li>初始空间映射 (Input Embedding)<br>模型内部有一个巨大的权重矩阵（Lookup Table），将离散的 ID 换成连续的向量。</li></ol><ul><li><strong>计算</strong>：每个 ID 去查表，换取一行 768 位的浮点数。</li><li><strong>注入位置信息</strong>：叠加 Position Encoding（位置编码）。</li><li><strong>维度</strong>：$3 \times 768$<blockquote><p><strong>状态</strong>：此时“我”、“爱”、“你”有了各自的语义，但彼此孤立。</p></blockquote></li></ul><ol start="3"><li>全双向交互 (Encoder Self-Attention) —— 核心步骤<br>这是 Embedding 产生“深度语义”的关键。BERT 类模型不设防，每一层都在做“全员大混战”。</li></ol><p><strong>以计算“爱”字在这一层的新向量为例：</strong></p><ol><li><strong>QKV 分裂</strong>：<ul><li>“爱”产生 $Q_2, K_2, V_2$；“我”产生 $K_1, V_1$；“你”产生 $K_3, V_3$。</li></ul></li><li><strong>双向对齐 (Bi-directional Scoring)</strong>：<ul><li>“爱”的 $Q_2$ 与全句所有人进行点积计算：<ul><li>$Score_{2,1}$ (爱 $\leftrightarrow$ 我)</li><li>$Score_{2,2}$ (爱 $\leftrightarrow$ 爱)</li><li>$Score_{2,3}$ (爱 $\leftrightarrow$ 你)</li></ul></li></ul></li><li><strong>加权融合</strong>：<ul><li>将分数通过 Softmax 转化为权重 $\alpha$，对所有人的 $V$ 进行加权求和。</li><li><strong>结果</strong>：新 $V_{爱} &#x3D; \alpha_1 V_1 + \alpha_2 V_2 + \alpha_3 V_3$</li></ul></li></ol><ul><li><strong>维度</strong>：依然是 $3 \times 768$<blockquote><p><strong>状态</strong>：此时的“爱”向量已经理解了它被夹在“我”和“你”之间。</p></blockquote></li></ul><ol start="4"><li>纵向特征提纯 (Deep Layers)<br>上述过程会重复 $L$ 层（如 BERT-base 为 12 层）。</li></ol><ul><li><strong>底层</strong>：提取基础语法和词性特征。</li><li><strong>高层</strong>：提取抽象的意图、情感和逻辑关系。</li><li><strong>维度</strong>：保持 $3 \times 768$。</li></ul><ol start="5"><li>语义归约 (Pooling)<br>经过多层揉捏后，我们需要把 $3 \times 768$ 的矩阵“压扁”成代表整句话的一个向量。</li></ol><ul><li><strong>做法一 (CLS)</strong>：取第一位特殊符号的输出向量（因为它在每一层都全量吸收了全句信息）。</li><li><strong>做法二 (Mean)</strong>：对所有位置的向量取平均值。</li><li><strong>最终维度</strong>：<strong>$1 \times 768$</strong></li></ul><p>对于多模态的embedding方法，基本思路是一致的，只不过是要把图片和图片对应的描述映射到同一个向量</p><ol start="3"><li>向量数据库的运作过程<br>（常见的向量数据库和他们采用的索引模式）<br>向量数据库和其他数据库一样，通常分为四层：存储层、索引层、查询层、服务层。<br>存储层负责存储向量数据，索引层负责建立向量索引，查询层负责响应查询实现查询优化，服务层负责客户端链接和交互等功能。<br>我们常见的向量数据库有：</li></ol><ul><li><p><strong>Chroma</strong>：基于本地存储，支持简单的索引模式（如 Flat Index）。</p></li><li><p><strong>Milvus</strong>：国产之光，支持分布式部署，适用于大规模向量检索。</p></li><li><p><strong>Pinecone</strong>：云端向量数据库，支持实时索引和查询，成本较高。</p></li><li><p><strong>Weaviate</strong> 是一款支持GraphQL的AI集成向量数据库，提供20+AI模块和多模态支持，社区活跃。<br>  向量数据库的工作模式如下：<br>  取：<br>  step1: 查询向量化<br>  当用户输入一个查询的时候，数据库首先会把查询交给embedding模块进行向量化。<br>  step2: 索引<br>  数据库不会和已经存取的向量进行全量对比，而是会使用检索算法结合索引进行快速匹配。具体的检索算法和索引后边会介绍。<br>  step3: 相似度计算<br>  在索引匹配到相似的一部分向量之后，数据库会根据相似度计算算法计算出最相似的向量。<br>  step4: 过滤<br>  数据库会根据元数据过滤掉一部分不和要求的向量，比如说根据存入的时间<br>  同时部分数据库会对向量进行重排序，找到最合适的向量<br>  step5: 返回结果<br>  数据库会返回向量对应的原文、路径、相似度得分。</p><p>  存：<br>  step1: 数据处理<br>  当用户输入数据的时候，数据库会首先将数据交给 embedding 模块进行向量化。<br>  step2: 建立索引<br>  数据库会根据配置建立索引，方便快速定位到相似的向量。数据库会同时存储向量、原始文本、元数据等信息。<br>  step3: 存储<br>  数据库会把向量化后的向量存储起来，等待后续的查询。</p></li></ul><p>4.向量数据库常见的索引算法</p><h3 id="📊-常见向量索引算法与底层库对比表"><a href="#📊-常见向量索引算法与底层库对比表" class="headerlink" title="📊 常见向量索引算法与底层库对比表"></a>📊 常见向量索引算法与底层库对比表</h3><table><thead><tr><th align="left">类别</th><th align="left">名称</th><th align="left">核心原理</th><th align="left">优势 (Pros)</th><th align="left">劣势 (Cons)</th><th align="left">适用场景</th></tr></thead><tbody><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>IVF</strong></td><td align="left"><strong>聚类分区</strong>：利用 K-Means 将空间划分为小区，搜索时只扫描邻近区域。</td><td align="left">内存占用低，索引速度快。</td><td align="left">搜索精度受限于聚类边界。</td><td align="left">中大规模数据的平衡选型。</td></tr><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>HNSW</strong></td><td align="left"><strong>分层图网络</strong>：构建多层“小世界”导航图，通过层级跳跃快速逼近目标。</td><td align="left"><strong>性能巅峰</strong>，检索延迟极低，召回率极高。</td><td align="left"><strong>内存消耗巨大</strong>，存储成本最高。</td><td align="left">RAG 生产环境、高并发实时检索。</td></tr><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>PQ</strong></td><td align="left"><strong>乘积量化</strong>：将长向量切段并压缩为短编码，实现大幅度“瘦身”。</td><td align="left"><strong>极度省空间</strong>（可压缩 10-100 倍），检索极快。</td><td align="left">精度损失明显，存在语义漂移。</td><td align="left">PB 级海量数据的低成本存储。</td></tr><tr><td align="left"><strong>算法</strong></td><td align="left"><strong>ANNOY</strong></td><td align="left"><strong>随机森林&#x2F;树</strong>：通过随机超平面不断二分空间，构建多棵索引树。</td><td align="left">支持静态文件内存映射（mmap），适合只读。</td><td align="left">不支持增量更新，必须重新构建索引。</td><td align="left">静态推荐系统、离线搜索、移动端。</td></tr><tr><td align="left"><strong>工具库</strong></td><td align="left"><strong>FAISS</strong></td><td align="left"><strong>高性能引擎</strong>：由 Meta 开发，集成了上述所有算法的底层优化库。</td><td align="left">支持 <strong>GPU 加速</strong>，支持多种算法复合（如 IVF-PQ）。</td><td align="left">仅为工具库，非分布式数据库，需二次开发。</td><td align="left">向量数据库底层引擎、算法调优。</td></tr></tbody></table><hr><h4 id="💡-快速选型指南："><a href="#💡-快速选型指南：" class="headerlink" title="💡 快速选型指南："></a>💡 快速选型指南：</h4><ol><li><strong>追求极致性能与准确率</strong> 🚀：首选 <strong>HNSW</strong>（目前 RAG 系统的主流）。</li><li><strong>数据量巨大但内存预算有限</strong> 💰：首选 <strong>IVF-PQ</strong> 组合。</li><li><strong>数据几乎不更新且需要低内存读写</strong> 🌲：考虑 <strong>ANNOY</strong>。</li><li><strong>需要进行亿级数据的大规模训练与加速</strong> 🛠️：直接使用 <strong>FAISS</strong>。</li></ol><p>如果想了解更多的技术细节，可以参考<a href="">!向量数据库常见的索引算法和检索算法</a></p><p>待补充</p>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Data for AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>LLM</tag>
      
      <tag>Data</tag>
      
      <tag>Agent</tag>
      
      <tag>数据人快速学 AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一文读懂最新的 NL2SQL 组件：Vanna.ai</title>
    <link href="/2026/01/28/Data-Analysis-Agent-20260128/"/>
    <url>/2026/01/28/Data-Analysis-Agent-20260128/</url>
    
    <content type="html"><![CDATA[<h3 id="1-什么是-Vanna-ai？"><a href="#1-什么是-Vanna-ai？" class="headerlink" title="1. 什么是 Vanna.ai？"></a>1. 什么是 Vanna.ai？</h3><p>Vanna.ai 是一个基于 LLM 的数据查询工具，可以快速查询数据库，并生成 SQL 查询语句。它的核心是<strong>基于 LLM 的数据查询工具</strong>，可以快速查询数据库，并生成 SQL 查询语句。<br>它的优势在于，可以将表结构、已经有过的查询语句、文档等等存在一个向量式数据库。等到用户查询的时候，根据用户的查询语句，从数据库中提取出相关的信息，拼入 prompt 中交给 LLM, 让 LLM 生成 SQL 查询语句,进一步将结果可视化，完成后续的问题。</p><h3 id="2-为什么要选用-Vanna-ai？"><a href="#2-为什么要选用-Vanna-ai？" class="headerlink" title="2. 为什么要选用 Vanna.ai？"></a>2. 为什么要选用 Vanna.ai？</h3><p>Vanna.ai 作为 NL2SQL 的一个常见架构。它具有以下几点优势:</p><ol><li><p>安全性：安全性主要体现在两方面。首先，不同的用户可以设置不同的用户组。不同的用户组分开训练向量数据库，admin用户组的查询结构，users用户组无法访问，可以防止用户从历史上下文里边越权获得星系。 其次，vanna.ai 做了很好的解耦，它实际上只是一个 SQL 生成工具，SQL实在自己的系统里边跑的。其他部分 AI 数据插件要求把数据库的链接地址、账号、密码都上传，极有可能发生数据泄漏。</p></li><li><p>灵活性：Vanna.ai 可以处理多种类型的数据库和查询，适用于不同的应用场景。很多业务分析人员并不了解数据库的结构，Vanna.ai 可以自动生成 SQL 查询语句，帮助非技术人员快速查询数据。</p></li><li><p>自我学习能力：每次成功的查询和历史对话都会被记录下来，作为后续的学习数据。Vanna.ai 会根据用户的查询和反馈，不断优化自己的模型，提高查询的准确性和效率。</p></li></ol><h3 id="3-Vanna-ai-的主要组件"><a href="#3-Vanna-ai-的主要组件" class="headerlink" title="3. Vanna.ai 的主要组件"></a>3. Vanna.ai 的主要组件</h3><p>Vanna.ai 主要有三部分组成，分别是：</p><ol><li><p><strong>执行器官</strong> <code>RunsqlTool</code>:即生产数据库，Vanna.ai 可以连接多种类型的数据库，如 MySQL、PostgreSQL、Oracle、SQL Server 等。</p></li><li><p><strong>记忆器官</strong> <code>ChromaAgentMemory</code>:即向量数据库，Vanna.ai 使用向量数据库来存储数据库中的元数据、历史查询结果、业务相关文档。向量数据库可以快速查找相似<br>的向量，并返回最相似的向量。每次查询的时候，LLM 会首先在向量数据库中找到与用户查询最相似的向量，然后把向量存储中的信息拼入 prompt 中，交给 LLM，生成 SQL 语句。</p></li><li><p><strong>思考器官</strong> <code>LLM</code>:Vanna.ai 使用 LLM 来生成 SQL 查询语句。LLM 可以理解自然语言，并生成符合语法规则的 SQL 查询语句。</p></li></ol><h3 id="4-Vanna-ai-的架构和运行模式"><a href="#4-Vanna-ai-的架构和运行模式" class="headerlink" title="4. Vanna.ai 的架构和运行模式"></a>4. Vanna.ai 的架构和运行模式</h3><p>这里我们参考官方文档给出的流程示意图：<br><img src="/images/Knowledge/Agent/Data_Analysis_Agent/Vanna_structure.png" alt="Vanna.ai 架构图"><br>Vanna.ai 的运行模式如下：</p><ol><li><p><strong>用户输入请求</strong>：用户提交自然语言问题（如：“广东省 VIP 会员去年的总消费额是多少？”）。</p></li><li><p><strong>语义向量化 (Embedding)</strong>：Vanna 调用 Embedding 模型（就是你刚才下载的那个 <code>all-MiniLM</code>），将问题转化为数学向量。</p></li><li><p><strong>知识检索 (RAG Retrieval)</strong>：Vanna 在向量数据库（你的 <code>chroma.sqlite3</code>）中检索与问题最相关的<strong>元数据</strong>。<strong>检索内容包括</strong>：建表语句 (DDL)、业务文档说明、以及历史累积的“问题-SQL”正确对。<strong>注入 Prompt</strong>：将检索到的“知识”拼入 Prompt，为 LLM 提示数据库的真实结构。</p></li><li><p><strong>SQL 生成 (Text-to-SQL)</strong>：LLM（如 DeepSeek）结合 Prompt 中的知识，将自然语言逻辑翻译成准确的 SQL 查询语句。</p></li><li><p><strong>本地执行 (Local Execution)</strong>：Vanna 的执行器（如 <code>SqliteRunner</code>）在<strong>用户本地环境</strong>连接数据库并运行 SQL。<strong>注意：真实业务数据始终不离开本地。</strong></p></li><li><p><strong>结果处理与可视化</strong>：将查询到的数据集（DataFrame）返回给前端，并根据需要调用绘图工具（如 Plotly）生成可视化图表。</p></li><li><p><strong>反馈与入库 (Feedback Loop)</strong>：用户或管理员对结果进行评价。如果 SQL 正确且高效，将其作为“金牌案例”存入向量数据库。</p></li><li><p><strong>持续学习 (Self-Learning)</strong>：随着正确案例的累积，Vanna 在处理同类问题时会优先匹配历史经验，从而跳过复杂的推理，提高查询的准确率和响应速度。</p></li></ol><p>整体来说Vanna 的核心是一个闭环系统。它通过检索增强（RAG）解决了 LLM 对私有数据库结构的‘信息缺位’问题。在执行端，它通过本地连接器（Runner）确保了数据不外流；在学习端，它通过向量数据库沉淀‘正确 SQL 经验’，实现越用越聪明的良性循环。</p><p>大家在做 NL2SQL 时，是倾向于把所有表结构丢给 LLM，还是通过语义检索只给它最相关的 5 张表？欢迎评论区交流。</p><p>作为一名大数据开发，我深知“懂业务”与“写代码”之间的鸿沟。Vanna.ai 的出现，不仅仅是省去了重复写 SQL 的时间，更是迈向“数据平民化”的重要一步。</p><p>目前我正致力于 NL2SQL 与 Data Agent 的企业级落地。在真实的大数据场景下，要让 AI 真正做到“指哪打哪”，需要一套严密的架构体系。后续我将在博客中持续分享相关的知识沉淀与实战经验，包括深度 RAG 架构优化、SQL 的“自愈”机制 (Self-Correction)、数据安全与动态脱敏、海量元数据的“精排”策略等。<br>如果你也对 Data + AI 的交叉领域感兴趣，欢迎关注程序员不急 <a href="https://www.norushcoder.com/">NoRushCoder.com</a>。后续我会持续分享相关的架构思考与技术沉淀，在这个 AI 浪潮奔涌的时代，我们一起“不疾不徐，稳步前行”。</p>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Data for AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>LLM</tag>
      
      <tag>Data</tag>
      
      <tag>Agent</tag>
      
      <tag>数据人快速学 AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>今日练字:2026-01-27</title>
    <link href="/2026/01/27/Practice_Handwriting_20260127/"/>
    <url>/2026/01/27/Practice_Handwriting_20260127/</url>
    
    <content type="html"><![CDATA[<p>今日份练字，偶尔拿出来写两笔<br>忘记拍照了</p>]]></content>
    
    
    <categories>
      
      <category>只要工整一点就好</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Practice_handwriting</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>备考雅思:2026-01-26</title>
    <link href="/2026/01/26/English-20260126/"/>
    <url>/2026/01/26/English-20260126/</url>
    
    <content type="html"><![CDATA[<p>今日份学习，加油加油<br><img src="/images/English/data_20260126.png" alt="今日学习数据"><br>今日英语学习依然在第一阶段：打基础+学习阅读技巧</p><ul><li><input disabled="" type="checkbox"> 单词过一遍</li><li><input disabled="" type="checkbox"> 阅读课过一遍</li></ul><h3 id="1-背单词"><a href="#1-背单词" class="headerlink" title="1.背单词"></a>1.背单词</h3><p>今日时间单词背诵37分钟，新词学习100个，复习27个。<br>继续加油</p><h3 id="2-学习雅思阅读的技巧"><a href="#2-学习雅思阅读的技巧" class="headerlink" title="2.学习雅思阅读的技巧"></a>2.学习雅思阅读的技巧</h3><h4 id="1-雅思阅读的考点："><a href="#1-雅思阅读的考点：" class="headerlink" title="1. 雅思阅读的考点："></a>1. 雅思阅读的考点：</h4><p>同义替换：同义单词、同义短语、同义句</p><p>问题里边用不同的表达来表示原文的意思</p><h4 id="2-备考雅思阅读方法：part1"><a href="#2-备考雅思阅读方法：part1" class="headerlink" title="2.备考雅思阅读方法：part1"></a>2.备考雅思阅读方法：part1</h4><p>2.1 总结同义替换</p><p>2.2 做题顺序</p><p><strong>Step1:预读题目画出关键词</strong><br>题型：</p><p>顺序题：填空、判断、单选 内容和题目的顺序基本一致<br><strong>做法</strong>：预读两道题目、画出关键词、读文章</p><p>乱序题：heading\which paragraph contain\匹配 <strong>做法</strong>：阅读全文之前预读题目、画出关键词</p><p>特殊题：多选、选标题、副标题 <strong>做法</strong>：预读题目，选项最后做</p><p><strong>Step2: 确定关键词</strong></p><p>能记住即可：时间、数字、大写、人名等</p><p><strong>Step3: 读文章内容</strong></p><p>定位关键词<br>关注转折词、并列词、因果关联词、举例子（例子前边是观点）、代词</p>]]></content>
    
    
    <categories>
      
      <category>备考雅思</category>
      
    </categories>
    
    
    <tags>
      
      <tag>English_Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>备考雅思:2026-01-23</title>
    <link href="/2026/01/23/English-20260123/"/>
    <url>/2026/01/23/English-20260123/</url>
    
    <content type="html"><![CDATA[<p>今日英语学习依然在第一阶段：打基础+学习阅读技巧</p><ul><li><input disabled="" type="checkbox"> 单词过一遍</li><li><input disabled="" type="checkbox"> 阅读课过一遍</li></ul><h3 id="1-背单词"><a href="#1-背单词" class="headerlink" title="1.背单词"></a>1.背单词</h3><p>今日时间充足，加油啊，继续好好学英语，我今年一定要把英语变成技能。<br>今日份学习，加油加油<br><img src="/images/English/data_20260123.png" alt="今日学习数据"></p><h3 id="2-雅思王听力"><a href="#2-雅思王听力" class="headerlink" title="2.雅思王听力"></a>2.雅思王听力</h3><p>今日听了chapter11 section2 的连读部分<br>很多单词不会<br>明天继续复习这一部分</p>]]></content>
    
    
    <categories>
      
      <category>备考雅思</category>
      
    </categories>
    
    
    <tags>
      
      <tag>English_Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>好的数据对于 LLM 有什么用？——从“数据搬运工”到“库内推理”的范式转移</title>
    <link href="/2026/01/23/good-data-for-llm/"/>
    <url>/2026/01/23/good-data-for-llm/</url>
    
    <content type="html"><![CDATA[<p>今天我们来聊一聊：“好的数据”对于 LLM 到底有什么用？</p><p>大家都知道数据是大模型的基础，质量决定效果。但随着 AI 卷得越来越厉害，算法同学的作用似乎越来越大，反观我们做数据的，作用好像慢慢被弱化了。</p><p>现在的痛点很真实：Java&#x2F;SQL 写不过 AI，业务理解干不过数分。<strong>那我们数据人还能干什么呢？</strong></p><p>其实 AI 跑得再快，现在也慢慢碰到“数据天花板”了。很多企业现在的瓶颈不再是“算力不够”，而是“数据供不上”。</p><h3 id="1-现有的-Data-for-AI-到底出了什么问题？"><a href="#1-现有的-Data-for-AI-到底出了什么问题？" class="headerlink" title="1. 现有的 Data for AI 到底出了什么问题？"></a>1. 现有的 Data for AI 到底出了什么问题？</h3><p>看上去企业数据资产不少，但真正能直接拿来训练、推理的比例并不高，主要是因为这几个坑：</p><ol><li><strong>数据类型对不上</strong>：现在企业大部分数据是二维表格，适合做报表。但模型更需要向量（表达语义）、图结构（表达关系）、时间序列（表达变化）。<strong>本质上，现有数据的组织方式和模型的需求“不兼容”。</strong></li><li><strong>维度不够</strong>：传统指标讲究“少而精”，字段得能解释。但模型往往靠大量稠密特征，很多特征单看没意义，组合起来才是宝。</li><li><strong>时效性太差</strong>：传统数据按天、按周更新，复盘够了，但推荐、风控这种实时决策，模型需要的是“现在”的数据，而不是“昨天”的。</li><li><strong>工具没用好</strong>：数据圈有很多成熟的实时处理、任务调度工具，但现在还没跟 AI 流程很好地合体。</li></ol><h3 id="2-具体的解决方案"><a href="#2-具体的解决方案" class="headerlink" title="2. 具体的解决方案"></a>2. 具体的解决方案</h3><p><strong>第一，从存储角度：</strong><br>得搞<strong>湖仓一体</strong>。在能存下多模态数据（图片、文档等）的基础上，增加快速调用的功能，别让数据躺在里面睡觉。</p><p><strong>第二，从推理角度：</strong></p><p>现在的方案太长：</p><blockquote><p><strong>数据库读 Page → 序列化发网络包 → 应用层反序列化 → 转为 Tensor → 最后才交给 GPU。</strong></p></blockquote><p>这就好比你在书架上找一本书，为了读它，你得先复印一份，装进快递盒寄回家，拆开后再翻译成母语，最后才开始读。</p><p><strong>我们更希望的是：</strong></p><ul><li><strong>零拷贝（Zero-Copy）思想</strong>：数据在数据库内存（Buffer Pool）里刚解开，别封装了，原地直接通过内置算子变向量。</li><li><strong>内存直接交付</strong>：Embedding 后的张量（Tensor）通过内存地址指针，直接甩给旁路挂载的推理引擎。</li></ul><p><strong>核心就是把计算向存储前移，能少搬数据就少搬。</strong></p><h3 id="3-我们可以利用哪些数据库的“老本行”优势？"><a href="#3-我们可以利用哪些数据库的“老本行”优势？" class="headerlink" title="3. 我们可以利用哪些数据库的“老本行”优势？"></a>3. 我们可以利用哪些数据库的“老本行”优势？</h3><ol><li><strong>索引能力</strong><br>做数据的都知道，索引能救命。如果没有索引，匹配问题就得全量扫描。<br><strong>举个例子：</strong> 如果提示词（Prompt）太长，模型每次都要重复计算 KV 矩阵，开销极大。但如果我们把这些值存入磁盘&#x2F;内存，并建立索引，下次就能直接命中之前的推理状态，从中间状态直接开跑。</li><li><strong>并行调度能力</strong><br>虽然并行是 GPU 的强项，但 GPU 必须从内存拉数据，搬运时间太长。数据库可以直接在内存里并行计算。而且如果把计算都看作“算子”，就能利用数据库成熟的任务调度和优先级管理，谁先跑谁后跑，管得明明白白。</li><li><strong>数据一致性（ACID）</strong><br>这是数据库的拿手好戏。如果直接在库内读向量做推理，只要数据库里的数据一变，模型拿到的结果立刻跟着变，业务响应极快，不用担心模型读到的是旧数据。</li><li><strong>硬约束（纠正幻觉）</strong><br>利用<strong>强 Schema 和约束</strong>。比如通过内置的图数据库算子，给推理加个“紧箍咒”。<br><strong>例子：</strong> 模型想推理“A 公司的 CEO 是谁”，向量检索可能搜到一堆八卦，但数据库会先查内部的关系图谱（确定的事实），如果是 B，就强制模型按这个输出。<strong>用“确定性”去纠正 AI 的“概率性”。</strong></li></ol><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>以后我们得解决这几个关键问题：</p><ol><li>怎么利用索引快速定位有效数据？</li><li>怎么利用数据库的大规模计算和贴近内存的特点，给训练和存储加速？</li><li>怎么利用事务能力，保证模型快速响应业务？</li><li>怎么利用数据库的“确定性”去纠偏？</li></ol><p>作为数据人的一份子，我很希望看到 AI 消费数据、理解数据，而数据反过来塑造 AI。</p><p><strong>不过说真的，如果这些都实现了，数据人是不是真的得去找新工作了？</strong></p>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Data for AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>LLM</tag>
      
      <tag>Data</tag>
      
      <tag>Agent</tag>
      
      <tag>数据人快速学 AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>简单了解期权</title>
    <link href="/2026/01/20/finance-20260120/"/>
    <url>/2026/01/20/finance-20260120/</url>
    
    <content type="html"><![CDATA[<h3 id="1-一句话说明：期权"><a href="#1-一句话说明：期权" class="headerlink" title="1. 一句话说明：期权"></a>1. 一句话说明：期权</h3><p>买方：花钱购买未来以固定价格买某样东西的权利</p><p>卖房：拿钱，但是必须在未来把某样资产以固定价格卖给买方</p><h3 id="2-举个例子："><a href="#2-举个例子：" class="headerlink" title="2. 举个例子："></a>2. 举个例子：</h3><p>现在股票A是100元一股，你有1000元，你如果直接买的话，只能买10股，假设未来三个月股票涨到150元，一共赚了$50*10&#x3D;500$元。</p><p>如果用期权，假设一股的权利金是10元，你可以购买100股的期权。<br>这个期权决定了，在未来三个月，你可以用110元购买股票。<br>你还有资金11000元，你可以用这11000元购买110股股票，假设股票涨到150元，一共赚了$（50-10）<em>100&#x3D;4000$元。<br>如果你没有其他资金，你也可以把这个期权卖出，期权现在的价格在40左右波动（别人买了这个期权，一股最少能省40，未来还可能更多），你可以$40</em>100&#x3D;4000$赚，净赚3000元。</p><h3 id="3-两个简单的期权模式："><a href="#3-两个简单的期权模式：" class="headerlink" title="3. 两个简单的期权模式："></a>3. 两个简单的期权模式：</h3><ol><li><p>看跌期权<br>期权有一个很神奇的地方，就是你可以卖出你没有的东西。<br>比如看跌期权。<br>假设你有9000元现金，股票A现在100元。你可以一股10元卖出自己的看跌期权，卖100股，担保：<br>在未来某个时间点，股票A价格不管跌到多少，我都以90元的价格购买。你承担了接盘的风险。<br>如果股票A的价格涨了，和你交易的人觉得卖给你亏了，那你赚了保证金1000元。<br>假设股票A的价格降到了85，你依然得以90元一股购买股票，你花9000元，获得了<em>85</em>100+1000&#x3D;9500元*。还是赚了500元。<br>但是跌的更低，可就亏了。</p></li><li><p>看涨期权<br>看涨期权和看跌期权是相反的。<br>如果你手里已经持有了一些股票（比如你打算长期持有的公司），你可以每个月给它们“收租”。每个月卖出一份远高于当前市价的看涨期权（Call）。只要股票没在短期内暴涨，你就白赚一份权利金。如果真的暴涨了，你就按高价把股票卖掉，反正你也赚了。这能极大地对冲你持股时的心理波动，在震荡市中，这部分“租金”往往能贡献 5%-10% 的额外年化收益。<br>想象一下，你是个硬件发烧友。英伟达发布了一款新显卡，现在市价 1000元。你手里暂时没钱，但你觉得三个月后因为 AI 爆发，这卡肯定会涨到 2000 元。你付给店老板 50元 签了一份合同：“三个月后的今天，我有权按 1000 元的价格从你这买一张显卡。”<br>如果大涨到 2000 元：你拿合同找老板，老板必须按 1000 元卖给你。你转手一卖，扣掉 50 元合同费，净赚 950 元！<br>如果没涨（甚至跌了）：你发现市场上这显卡只要 800 元了。你肯定不会按 1000 元买，你直接撕毁合同，损失就是那 50元 的合同费。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Finance</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>Finance</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>备考雅思:2026-01-20</title>
    <link href="/2026/01/20/English-20260120/"/>
    <url>/2026/01/20/English-20260120/</url>
    
    <content type="html"><![CDATA[<p>今日份学习，加油加油<br><img src="/images/English/data_20260120.png" alt="今日学习数据"><br>今日英语学习依然在第一阶段：打基础+学习阅读技巧</p><ul><li><input disabled="" type="checkbox"> 单词过一遍</li><li><input disabled="" type="checkbox"> 阅读课过一遍</li></ul><h3 id="1-背单词"><a href="#1-背单词" class="headerlink" title="1.背单词"></a>1.背单词</h3><p>今日时间充足，加油啊，继续好好学英语，我今年一定要把英语变成技能。</p>]]></content>
    
    
    <categories>
      
      <category>备考雅思</category>
      
    </categories>
    
    
    <tags>
      
      <tag>English_Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>life_20260118</title>
    <link href="/2026/01/18/life-20260118/"/>
    <url>/2026/01/18/life-20260118/</url>
    
    <content type="html"><![CDATA[<p>今晚沉浸于《WhynotTV》何泰然与翁家翌的深度对话，仿佛目睹两颗清华星辰的碰撞。他们的思维密度与认知高度，令我这样的普通听众唯有仰望的份。</p><p>虽非算法领域从业者，但我对翁家翌在开源世界的贡献怀有深深的敬意。正是这些先行者留下的开源项目与经验沉淀，为无数像我这样非科班、非名校出身的探索者，点亮了前行的微光。</p><p>这期播客最触动我的，是翁家翌那套清晰而稳固的个人评价体系。他很早就构建了一套内在的坐标系，让自己能够最大程度地摆脱外界评价体系的引力，按照自己的逻辑去生活、去行动。这样的活法未必轻松，但一定足够自洽。</p><p>当何泰然问及是否担心自己的这套体系未来也会演变成像GPA那样令人窒息的内卷时，翁家翌的回答掷地有声：“我不害怕。”</p><p>我理解，这两套体系的核心区别在于，社会主流的评价体系（如GPA、地位）往往带有零和博弈的侵略性——你的拥有，意味着我的稀缺。而翁家翌的内在体系，则指向一种正和的、共同成长的共赢状态。</p><p>我或许无法企及翁神那般卓越的代码造诣与行业影响力，也无法构建他那样宏大的个人坐标系。但我愿意从微小处着手，建立属于自己的朴素标准。</p><p><strong>比昨天懂得更多，成为更好的自己</strong>。</p>]]></content>
    
    
    <categories>
      
      <category>Thoughts</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Life</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>备考雅思:2026-01-17</title>
    <link href="/2026/01/17/English_20260116/"/>
    <url>/2026/01/17/English_20260116/</url>
    
    <content type="html"><![CDATA[<p>今日份学习，加油加油<br><img src="/images/English/data_20260117.png" alt="今日学习数据"><br>今日英语学习依然在第一阶段：打基础+学习阅读技巧</p><ul><li><input disabled="" type="checkbox"> 单词过一遍</li><li><input disabled="" type="checkbox"> 阅读课过一遍</li></ul><h3 id="1-背单词"><a href="#1-背单词" class="headerlink" title="1.背单词"></a>1.背单词</h3><p>今日时间不够<br>复习单词25min。<br>最近好忙，漫漫学习路，加油啊。</p>]]></content>
    
    
    <categories>
      
      <category>备考雅思</category>
      
    </categories>
    
    
    <tags>
      
      <tag>English_Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>什么是Agent Skills</title>
    <link href="/2026/01/17/Agent-Skills-20260117/"/>
    <url>/2026/01/17/Agent-Skills-20260117/</url>
    
    <content type="html"><![CDATA[<h1 id="Agent-Skills：大模型能力的渐进式封装与按需加载"><a href="#Agent-Skills：大模型能力的渐进式封装与按需加载" class="headerlink" title="Agent Skills：大模型能力的渐进式封装与按需加载"></a>Agent Skills：大模型能力的渐进式封装与按需加载</h1><h3 id="1-前置：什么是-MCP？"><a href="#1-前置：什么是-MCP？" class="headerlink" title="1. 前置：什么是 MCP？"></a>1. 前置：什么是 MCP？</h3><p>MCP（Model Context Protocol，模型上下文协议）本质上是一个大模型调用工具的协议标准，相当于一套通用的口令去调用大模型。</p><p>简单来说，MCP 是一个对于被调用工具和 LLM 来说都简化了的调用口令。LLM 之前调用工具需要生成一串很长的 Token 作为 API 调用接口，再由专门的代码去解析这个 API 找到参数。这里就会遇到一个痛点：不同工具的 API 规范不一样，生成极易出错，而且每次都需要给很长的 Prompt。</p><p><strong>例如，传统查询天气的 Prompt 可能长这样：</strong></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;action&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;weather_service_api_v4_search&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;method&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;GET&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;endpoint&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;[https://api.weather.com/v1/current](https://api.weather.com/v1/current)&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;auth_type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;bearer_token&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;parameters&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;location_query&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Shanghai, CN&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;unit_system&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;metric&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;data_fields&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-string">&quot;temp&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;humidity&quot;</span><span class="hljs-punctuation">,</span> <span class="hljs-string">&quot;wind_speed&quot;</span><span class="hljs-punctuation">]</span><br>  <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br><br></code></pre></td></tr></table></figure><p>有了 MCP，工具侧暴露通用的、简洁的 API，调用格式高度一致，大大减少了 LLM 侧的调用成本：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>  <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;get_weather&quot;</span><span class="hljs-punctuation">,</span><br>  <span class="hljs-attr">&quot;arguments&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span> <span class="hljs-attr">&quot;location&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;Shanghai&quot;</span> <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br><br></code></pre></td></tr></table></figure><p>所有的解析、轮询、调用都在 MCP 服务器上完成。目前 Cursor、Claude Desktop 等生态已广泛应用。</p><p><strong>但随着工具量的增加，MCP 也会遇到瓶颈：</strong></p><ul><li><strong>能力不足</strong>：面对复杂任务，智能体需要具备领域知识（比如会调数据库接口但不一定会写 SQL）。</li><li><strong>上下文爆炸</strong>：任务复杂化后，Prompt 依然会累积大量内容，严重影响模型性能。</li></ul><p><strong>Agent Skills 应运而生。</strong></p><hr><h3 id="2-Agent-Skills-是什么？"><a href="#2-Agent-Skills-是什么？" class="headerlink" title="2. Agent Skills 是什么？"></a>2. Agent Skills 是什么？</h3><p>Agent Skills 是标准化的程序性知识封装格式。它将知识和工具解离开：<strong>MCP 负责调用工具，Skills 负责封装知识。</strong> 通过渐进式披露，实现知识的按需逐步加载。</p><h4 id="🛡️-第一层：元数据层-Metadata"><a href="#🛡️-第一层：元数据层-Metadata" class="headerlink" title="🛡️ 第一层：元数据层 (Metadata)"></a>🛡️ 第一层：元数据层 (Metadata)</h4><p>每一个技能文件夹内都有一个 <code>skill.md</code> 文件。顶部的 <code>frontmatter</code> 部分定义了技能的简单描述：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">name:</span> <span class="hljs-string">paper_searcher</span><br><span class="hljs-attr">description:</span> <span class="hljs-string">专门用于搜索</span> <span class="hljs-string">arXiv</span> <span class="hljs-string">和</span> <span class="hljs-string">Google</span> <span class="hljs-string">Scholar</span> <span class="hljs-string">上的最新学术论文，支持按关键词和年份筛选。</span><br><span class="hljs-attr">version:</span> <span class="hljs-number">1.0</span><span class="hljs-number">.0</span><br><span class="hljs-attr">category:</span> <span class="hljs-string">academic</span><br><span class="hljs-attr">author:</span> <span class="hljs-string">your_name</span><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br></code></pre></td></tr></table></figure><p>在 MCP 框架下，初始化时通常要发送完整的参数定义（JSON Schema）。</p><ul><li><strong>MCP 做法</strong>：加载一段约 150 Tokens 的详细 JSON。如果有 10 个工具，连接瞬间就丢掉 2000 个 Token。</li><li><strong>Skills 做法</strong>：仅发送元数据描述，约占 20-30 Tokens。</li></ul><p><img src="/images/Knowledge/Agent/Agent_Skills/contrast.jpg" alt="Agent Skills"></p><h4 id="🛡️-第二层：技能主体"><a href="#🛡️-第二层：技能主体" class="headerlink" title="🛡️ 第二层：技能主体"></a>🛡️ 第二层：技能主体</h4><p>当智能体解析用户指令，发现匹配某个技能时，才会读取完整的 <code>skill.md</code> 文件，获得该技能完整的 MCP 调用接口。通过这种方式，Token 消耗量被大大压缩。</p><h4 id="🛡️-第三层：附加资源-文件夹即技能"><a href="#🛡️-第三层：附加资源-文件夹即技能" class="headerlink" title="🛡️ 第三层：附加资源 (文件夹即技能)"></a>🛡️ 第三层：附加资源 (文件夹即技能)</h4><p>这是这套架构最强悍的地方：<strong>一个技能就是一个全功能的上下文包。</strong></p><p>以<strong>毕业论文格式审查与润色</strong>技能为例，文件夹结构如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs text">/skills/paper_polisher/<br>├── SKILL.md             # 核心元数据与激活逻辑<br>├── thesis_rules.json    # 复杂的学校排版规范<br>├── sample_bad_vs_good.md # 润色对照示例 (Few-shot)<br>├── check_format.py      # LaTeX 语法检测脚本<br>└── terminology.csv      # 领域专业词汇对照表<br><br></code></pre></td></tr></table></figure><p>当用户提出需求时，系统会按需加载资源：加载 <code>thesis_rules.json</code> 获取法律依据，加载 <code>terminology.csv</code> 对齐专业术语，甚至运行 <code>check_format.py</code> 进行硬核检测。</p><hr><h3 id="3-Agent-Skills-的核心优势"><a href="#3-Agent-Skills-的核心优势" class="headerlink" title="3. Agent Skills 的核心优势"></a>3. Agent Skills 的核心优势</h3><h4 id="①-极高的语义精准度-Few-shot-Support"><a href="#①-极高的语义精准度-Few-shot-Support" class="headerlink" title="① 极高的语义精准度 (Few-shot Support)"></a>① 极高的语义精准度 (Few-shot Support)</h4><p>MCP 依赖 JSON 描述，适合定义类型，但不擅长描述“风格”。在 JSON 里强插示例会造成 Token 冗余。<br><strong>Skills 的优势</strong>：通过引用 <code>samples.md</code>，在干活时甩给 LLM 几个<strong>顶级范例</strong>（Few-shot Prompting）。LLM 不再盲目猜测，而是有了<strong>手感</strong>，输出质量从 70 分直奔 95 分。</p><h4 id="②-跨语言的工具集成-Hybrid-Execution"><a href="#②-跨语言的工具集成-Hybrid-Execution" class="headerlink" title="② 跨语言的工具集成 (Hybrid Execution)"></a>② 跨语言的工具集成 (Hybrid Execution)</h4><p>文件夹可以携带 Python 或脚本。对于规则极强的任务（如公式闭合检查），脚本比 LLM 更快更准。技能可以先跑脚本，再让 LLM 总结。</p><p><img src="/images/Knowledge/Agent/Agent_Skills/skills_help_ai.jpg" alt="Agent Skills"></p><h4 id="③-私有化与版本隔离"><a href="#③-私有化与版本隔离" class="headerlink" title="③ 私有化与版本隔离"></a>③ 私有化与版本隔离</h4><p>每个文件夹独立。你可以为不同的技能各做一个包，引用不同词库，互不干扰，像插拔式硬盘一样方便。</p><h4 id="④-动态上下文管理-Smart-Context-Loading"><a href="#④-动态上下文管理-Smart-Context-Loading" class="headerlink" title="④ 动态上下文管理 (Smart Context Loading)"></a>④ 动态上下文管理 (Smart Context Loading)</h4><p>系统根据需求只加载文件夹里的某一个文件。相比 MCP 的全量不可拆分，Skills 能进一步节省每一轮对话的成本。</p><hr><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Agent Skills 通过<strong>渐进式披露 + 技能相关文件打包</strong>的方式，实现了 Agent 的按需加载，解决了 MCP 在复杂场景下的知识匮乏与上下文冗余问题。</p>]]></content>
    
    
    <categories>
      
      <category>Knowledge</category>
      
      <category>Agent</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge</tag>
      
      <tag>LLM</tag>
      
      <tag>Data</tag>
      
      <tag>Agent</tag>
      
      <tag>数据人快速学 AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>今日练字:2026-01-15</title>
    <link href="/2026/01/15/Practice_Handwriting_20260115/"/>
    <url>/2026/01/15/Practice_Handwriting_20260115/</url>
    
    <content type="html"><![CDATA[<p>今日份练字，偶尔拿出来写两笔<br><img src="/images/Handwriting/handwriting_20260115.jpg" alt="今日练字"></p>]]></content>
    
    
    <categories>
      
      <category>只要工整一点就好</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Practice_handwriting</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>备考雅思:2026-01-15</title>
    <link href="/2026/01/15/English_20260115/"/>
    <url>/2026/01/15/English_20260115/</url>
    
    <content type="html"><![CDATA[<p>今日份学习，加油加油<br><img src="/images/English/data_20260115.png" alt="今日学习数据"><br>今日英语学习依然在第一阶段：打基础+学习阅读技巧</p><ul><li><input disabled="" type="checkbox"> 单词过一遍</li><li><input disabled="" type="checkbox"> 阅读课过一遍</li></ul><h3 id="1-背单词"><a href="#1-背单词" class="headerlink" title="1.背单词"></a>1.背单词</h3><p>今日时间不够<br>复习单词15min 进度</p><h3 id="2-语料库"><a href="#2-语料库" class="headerlink" title="2.语料库"></a>2.语料库</h3><p>听15min 检查10min</p><p>chapter 11 section2</p><p>单词部分听完并学习了新的单词 明天复习</p>]]></content>
    
    
    <categories>
      
      <category>备考雅思</category>
      
    </categories>
    
    
    <tags>
      
      <tag>English_Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo上传问题</title>
    <link href="/2026/01/15/Hexo_Upload_Problem/"/>
    <url>/2026/01/15/Hexo_Upload_Problem/</url>
    
    <content type="html"><![CDATA[<p>解决了一个小问题：hexo上传的时候出现两个问题：</p><ol><li>只有标题没有内容</li><li>首页的tag里边显示是example&#x2F;&#x2F;&#x2F;</li></ol><p>因为在<code>_config.yml</code>还没有设定</p><figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs ldif"><span class="hljs-comment"># URL</span><br><span class="hljs-comment">## Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27;</span><br><span class="hljs-attribute">url</span>: <br><span class="hljs-attribute">permalink</span>: <br></code></pre></td></tr></table></figure><p>改过来就可以了</p>]]></content>
    
    
    <categories>
      
      <category>Issues</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Issues</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>今天我对番茄钟的一点重新认识</title>
    <link href="/2026/01/15/Knowledge_About_Pomodoro_Techniquet/"/>
    <url>/2026/01/15/Knowledge_About_Pomodoro_Techniquet/</url>
    
    <content type="html"><![CDATA[<p>番茄钟（Pomodoro Technique）是由 Francesco Cirillo 在 1980 年代提出的一种时间管理方法：将工作划分为 25 分钟的专注时段（称为一个“番茄”），之后休息 5 分钟；每完成四个番茄，进行一次 15–30 分钟的长休息。其核心理念是通过「专注 + 休息」的循环，提升效率、减少分心、避免疲劳，尤其适合容易走神、希望培养专注力的人。</p><p>我一直用番茄钟训练自己的专注力，却始终没体验到公众号或营销号里描述的那种“神奇效果”。相反，我常常感到疲于奔命——像一头必须在限定时间内耕完地的老黄牛，鞭子还没到，就开始喘着粗气。越赶越急，任务反而更难完成。更糟的是，那 5 分钟的休息常常失控：一刷手机就停不下来，结果不仅没恢复精力，还进一步损耗了专注力。</p><p>我的典型模式是这样的：<br>“现在要写一段代码 → 设定 25 分钟 → 时间到，休息 5 分钟 → 任务没做完 → 再来一个番茄……”</p><p>直到今天读到一篇文章，我才恍然大悟：番茄钟真正的价值，或许不是“逼你专注”，而是一个“时间评估工具”。<br>它帮助你将有限的时间片，合理分配给不同的任务，从而看清自己一天的真实产出。</p><p>反思下来，我的问题其实出在两点：</p><ol><li><p>目标模糊，本末倒置<br>我总是“先有时间，后找任务”——盯着 25 分钟倒计时，却没想清楚“这 25 分钟到底要完成什么”。正确的做法应该是：先明确任务，再用番茄钟去分配时间。</p></li><li><p>忽视了番茄钟的“计量”功能<br>番茄钟的本质是“有效工作单位”。一天能完成多少个番茄，直接反映了你的真实高效时长。<br>比如，我可能“工作”了 8 小时，但有效番茄只有 4–5 个。这个数字让我看清：时间去哪儿了？哪些环节在浪费精力？如何优化节奏？</p></li></ol><p>番茄钟不是枷锁，而是镜子。<br>它照见的不是你的懒惰，而是你与时间的真实关系。</p><p>共勉。</p>]]></content>
    
    
    <categories>
      
      <category>方法论</category>
      
      <category>时间管理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Tips</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
